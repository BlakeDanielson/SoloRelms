"""
Complete Orchestration System Test
Validates the entire AI DM pipeline: Session ‚Üí Action ‚Üí AI ‚Üí Parsing ‚Üí State ‚Üí Response
"""

import os
import sys
import asyncio
import json
from datetime import datetime
from typing import Dict, Any

# Add the backend directory to the path for imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from services.game_orchestrator import get_game_orchestrator, ActionResult, GamePhase
    from services.ai_service import ai_service
    from services.redis_service import redis_service  
    from services.response_parser import response_parser
    from api.dice import DiceRoll
    print("‚úÖ Successfully imported all orchestration services")
except ImportError as e:
    print(f"‚ùå Import error: {e}")
    sys.exit(1)


class OrchestrationTestSuite:
    """Comprehensive test suite for the complete orchestration system"""
    
    def __init__(self):
        self.test_results = []
        self.mock_db = None  # Would normally be a test database session
        
    async def run_all_tests(self):
        """Run the complete test suite"""
        print("üöÄ Starting Complete Orchestration Test Suite")
        print("=" * 70)
        
        tests = [
            ("Service Health Checks", self.test_service_health),
            ("Session Creation & Initialization", self.test_session_creation),
            ("Basic Player Action Processing", self.test_basic_action_processing),
            ("Dice Roll Integration", self.test_dice_integration),
            ("Complex Multi-Turn Scenario", self.test_complex_scenario),
            ("Error Handling & Recovery", self.test_error_handling),
            ("Performance & Caching", self.test_performance_caching),
            ("State Synchronization", self.test_state_synchronization)
        ]
        
        for test_name, test_method in tests:
            print(f"\nüìã Running: {test_name}")
            print("-" * 40)
            
            try:
                result = await test_method()
                self.test_results.append((test_name, result, None))
                status = "‚úÖ PASSED" if result else "‚ùå FAILED"
                print(f"{status}: {test_name}")
            except Exception as e:
                self.test_results.append((test_name, False, str(e)))
                print(f"‚ùå ERROR: {test_name} - {str(e)}")
        
        self.print_final_results()
    
    async def test_service_health(self) -> bool:
        """Test that all underlying services are healthy"""
        print("üîç Testing service health...")
        
        try:
            # Test AI service health
            ai_health = ai_service.health_check()
            print(f"   AI Service: {ai_health.get('status', 'unknown')}")
            
            # Test Redis service health
            redis_health = await redis_service.health_check()
            print(f"   Redis Service: {redis_health.get('status', 'unknown')}")
            
            # Test response parser
            test_parse = response_parser.parse_response("Test health check")
            print(f"   Response Parser: Ready (confidence: {test_parse.confidence_score:.2f})")
            
            print("‚úÖ All services are healthy")
            return True
            
        except Exception as e:
            print(f"‚ùå Service health check failed: {str(e)}")
            return False
    
    async def test_session_creation(self) -> bool:
        """Test game session creation and initialization"""
        print("üéÆ Testing session creation...")
        
        try:
            # Mock character data since we don't have a real DB
            mock_character = type('MockCharacter', (), {
                'id': 1,
                'name': 'Test Hero',
                'class_name': 'Fighter',
                'level': 3,
                'race': 'Human',
                'current_hp': 25,
                'max_hp': 30,
                'armor_class': 16
            })()
            
            # Simulate session creation (would normally use real orchestrator)
            session_id = f"test_session_{int(datetime.now().timestamp())}"
            
            # Test Redis session creation
            await redis_service.create_game_session(
                session_id=session_id,
                user_id="test_user",
                character_id=1,
                story_arc_id=None
            )
            
            # Verify session was created
            session = await redis_service.get_game_session(session_id)
            if session:
                print(f"‚úÖ Session created: {session_id}")
                print(f"   User: {session.user_id}")
                print(f"   Character: {session.character_id}")
                return True
            else:
                print("‚ùå Session creation failed")
                return False
                
        except Exception as e:
            print(f"‚ùå Session creation error: {str(e)}")
            return False
    
    async def test_basic_action_processing(self) -> bool:
        """Test basic player action processing pipeline"""
        print("‚ö° Testing basic action processing...")
        
        try:
            # Mock player action
            player_action = "I examine the ancient door for any traps or mechanisms."
            
            # Test AI response generation (simulated)
            mock_ai_response = """
You carefully examine the ancient wooden door. Its surface is carved with intricate 
runes that seem to pulse with a faint magical energy. Make a Perception check 
(1d20 + your Wisdom modifier) to notice any hidden mechanisms.

As you run your hands along the frame, you feel a slight depression behind one of 
the runes. This could be a trigger mechanism.

ACTIONS:
- examination: Player examines the door thoroughly
- discovery: Found hidden mechanism behind rune

STATE_CHANGES:
- character.investigation_progress: 0 -> 1

DICE_ROLLS:
- 1d20+WIS: Perception check to find hidden mechanisms
            """
            
            # Test response parsing
            parsed_response = response_parser.parse_response(mock_ai_response)
            
            print(f"‚úÖ AI Response generated ({len(mock_ai_response)} chars)")
            print(f"‚úÖ Response parsed (confidence: {parsed_response.confidence_score:.2f})")
            print(f"   Actions found: {len(parsed_response.actions)}")
            print(f"   State changes: {len(parsed_response.state_changes)}")
            print(f"   Dice rolls required: {len(parsed_response.dice_rolls)}")
            
            # Verify expected elements
            has_dice_roll = any(roll.dice_expression == "1d20+WIS" for roll in parsed_response.dice_rolls)
            has_action = len(parsed_response.actions) > 0
            has_narrative = len(parsed_response.narrative_text) > 100
            
            if has_dice_roll and has_action and has_narrative:
                print("‚úÖ All expected elements found in parsed response")
                return True
            else:
                print("‚ö†Ô∏è Some expected elements missing from parsed response")
                return False
                
        except Exception as e:
            print(f"‚ùå Action processing error: {str(e)}")
            return False
    
    async def test_dice_integration(self) -> bool:
        """Test dice roll integration with AI responses"""
        print("üé≤ Testing dice integration...")
        
        try:
            # Create mock dice roll
            dice_roll = DiceRoll(
                expression="1d20+4",
                result=17,
                modifier=4,
                roll_type="perception"
            )
            
            # Test AI response with dice results (simulated)
            mock_ai_response_with_dice = """
Your Perception check (17) succeeds! You notice a small, almost invisible button 
hidden behind the carved rune. The button appears to be part of a complex locking 
mechanism. 

You also spot tiny holes around the door frame - likely dart traps that would 
trigger if the door were forced open.

Your careful examination has revealed the door's secrets without setting off any traps.

STATE_CHANGES:
- character.current_location: hallway -> secret_door_discovered
- story.clues_found: adds "hidden_button_mechanism"

ACTIONS:
- successful_perception: Found hidden button and dart traps
- safe_discovery: No traps triggered during examination
            """
            
            parsed_with_dice = response_parser.parse_response(mock_ai_response_with_dice)
            
            print(f"‚úÖ Dice roll created: {dice_roll.expression} = {dice_roll.result}")
            print(f"‚úÖ AI response with dice result parsed")
            print(f"   Location changes: {len([c for c in parsed_with_dice.state_changes if c.property_name == 'current_location'])}")
            print(f"   Story progression: {len([c for c in parsed_with_dice.state_changes if c.entity_type == 'story'])}")
            
            # Verify dice integration worked
            has_success_outcome = "succeeds" in mock_ai_response_with_dice.lower()
            has_state_changes = len(parsed_with_dice.state_changes) > 0
            
            if has_success_outcome and has_state_changes:
                print("‚úÖ Dice integration working correctly")
                return True
            else:
                print("‚ö†Ô∏è Dice integration may have issues")
                return False
                
        except Exception as e:
            print(f"‚ùå Dice integration error: {str(e)}")
            return False
    
    async def test_complex_scenario(self) -> bool:
        """Test a complex multi-turn scenario with various game elements"""
        print("üé≠ Testing complex multi-turn scenario...")
        
        try:
            scenario_turns = [
                {
                    "action": "I sneak toward the goblin camp to scout their numbers",
                    "expected_elements": ["stealth_check", "reconnaissance"]
                },
                {
                    "action": "I cast Magic Missile at the goblin leader",
                    "expected_elements": ["spell_attack", "damage", "combat_initiative"]
                },
                {
                    "action": "I try to persuade the captured villager to stay calm",
                    "expected_elements": ["charisma_check", "npc_interaction"]
                }
            ]
            
            session_id = f"complex_test_{int(datetime.now().timestamp())}"
            turn_results = []
            
            for i, turn in enumerate(scenario_turns):
                print(f"   Turn {i+1}: {turn['action'][:50]}...")
                
                # Simulate processing this turn
                mock_response = f"""
The action '{turn['action']}' unfolds dramatically. The situation evolves 
as your character takes decisive action in this challenging scenario.

Make a skill check relevant to your action to determine the outcome.

ACTIONS:
- turn_action: {turn['action']}

DICE_ROLLS:
- 1d20+MOD: Skill check for action success
                """
                
                parsed = response_parser.parse_response(mock_response)
                turn_results.append({
                    'turn': i+1,
                    'action': turn['action'],
                    'parsed_confidence': parsed.confidence_score,
                    'elements_found': len(parsed.actions) + len(parsed.dice_rolls)
                })
            
            print(f"‚úÖ Processed {len(scenario_turns)} complex turns")
            for result in turn_results:
                print(f"   Turn {result['turn']}: confidence {result['parsed_confidence']:.2f}, elements {result['elements_found']}")
            
            # Verify all turns processed successfully
            avg_confidence = sum(r['parsed_confidence'] for r in turn_results) / len(turn_results)
            total_elements = sum(r['elements_found'] for r in turn_results)
            
            if avg_confidence > 0.7 and total_elements >= len(scenario_turns):
                print("‚úÖ Complex scenario handling successful")
                return True
            else:
                print("‚ö†Ô∏è Complex scenario may need improvements")
                return False
                
        except Exception as e:
            print(f"‚ùå Complex scenario error: {str(e)}")
            return False
    
    async def test_error_handling(self) -> bool:
        """Test error handling and recovery mechanisms"""
        print("üõ°Ô∏è Testing error handling...")
        
        try:
            error_scenarios = [
                {
                    "name": "Invalid AI Response",
                    "input": "",
                    "should_recover": True
                },
                {
                    "name": "Malformed Dice Expression", 
                    "input": "Roll a 99d999+infinity for ultimate power!",
                    "should_recover": True
                },
                {
                    "name": "Very Long Response",
                    "input": "The dragon roars magnificently! " * 1000,
                    "should_recover": True
                }
            ]
            
            recovery_count = 0
            
            for scenario in error_scenarios:
                print(f"   Testing: {scenario['name']}")
                
                try:
                    # Test response parser resilience
                    parsed = response_parser.parse_response(scenario['input'])
                    
                    if scenario['should_recover']:
                        print(f"     ‚úÖ Recovered gracefully (confidence: {parsed.confidence_score:.2f})")
                        if parsed.parsing_errors:
                            print(f"     ‚ö†Ô∏è Logged {len(parsed.parsing_errors)} errors")
                        recovery_count += 1
                    else:
                        print(f"     ‚ö†Ô∏è Should have failed but recovered")
                        
                except Exception as e:
                    if scenario['should_recover']:
                        print(f"     ‚ùå Failed to recover: {str(e)}")
                    else:
                        print(f"     ‚úÖ Properly rejected: {str(e)}")
                        recovery_count += 1
            
            success_rate = recovery_count / len(error_scenarios)
            print(f"‚úÖ Error recovery rate: {success_rate*100:.1f}%")
            
            return success_rate >= 0.8
            
        except Exception as e:
            print(f"‚ùå Error handling test failed: {str(e)}")
            return False
    
    async def test_performance_caching(self) -> bool:
        """Test performance and caching effectiveness"""
        print("‚ö° Testing performance and caching...")
        
        try:
            # Test data caching
            test_character_data = {
                'id': 1,
                'name': 'Performance Test Hero',
                'class_name': 'Wizard',
                'level': 5,
                'current_hp': 40,
                'max_hp': 45
            }
            
            # Time cache operations
            start_time = datetime.now()
            
            # Cache character data
            await redis_service.cache_character_data(1, test_character_data, redis_service.CacheExpiry.SHORT)
            cache_time = (datetime.now() - start_time).total_seconds()
            
            # Retrieve cached data
            start_time = datetime.now()
            cached_data = await redis_service.get_character_cache(1)
            retrieve_time = (datetime.now() - start_time).total_seconds()
            
            print(f"‚úÖ Cache write time: {cache_time*1000:.2f}ms")
            print(f"‚úÖ Cache read time: {retrieve_time*1000:.2f}ms")
            
            # Verify data integrity
            if cached_data and cached_data.get('name') == test_character_data['name']:
                print("‚úÖ Cache data integrity verified")
                cache_working = True
            else:
                print("‚ùå Cache data integrity failed")
                cache_working = False
            
            # Test response parsing performance
            large_response = "The adventure continues with epic encounters! " * 100
            start_time = datetime.now()
            parsed_large = response_parser.parse_response(large_response)
            parse_time = (datetime.now() - start_time).total_seconds()
            
            print(f"‚úÖ Large response parse time: {parse_time*1000:.2f}ms")
            
            # Performance thresholds
            cache_fast = cache_time < 0.1 and retrieve_time < 0.1
            parse_fast = parse_time < 1.0
            
            if cache_working and cache_fast and parse_fast:
                print("‚úÖ Performance and caching are optimal")
                return True
            else:
                print("‚ö†Ô∏è Performance may need optimization")
                return False
                
        except Exception as e:
            print(f"‚ùå Performance test error: {str(e)}")
            return False
    
    async def test_state_synchronization(self) -> bool:
        """Test state synchronization between cache and game logic"""
        print("üîÑ Testing state synchronization...")
        
        try:
            # Create test session
            test_session_id = f"sync_test_{int(datetime.now().timestamp())}"
            
            await redis_service.create_game_session(
                session_id=test_session_id,
                user_id="sync_test_user",
                character_id=1,
                story_arc_id=None
            )
            
            # Test character state updates
            initial_hp = 30
            character_data = {
                'id': 1,
                'name': 'Sync Test Character',
                'current_hp': initial_hp,
                'max_hp': 35
            }
            
            await redis_service.cache_character_data(1, character_data, redis_service.CacheExpiry.MEDIUM)
            
            # Simulate HP change through game logic
            hp_change = -5  # Take damage
            updated_character = character_data.copy()
            updated_character['current_hp'] = max(0, initial_hp + hp_change)
            
            await redis_service.cache_character_data(1, updated_character, redis_service.CacheExpiry.MEDIUM)
            
            # Verify synchronization
            synced_data = await redis_service.get_character_cache(1)
            
            if synced_data and synced_data.get('current_hp') == 25:
                print(f"‚úÖ HP change synchronized: {initial_hp} ‚Üí {synced_data.get('current_hp')}")
                
                # Test session state
                session_check = await redis_service.get_game_session(test_session_id)
                if session_check:
                    print("‚úÖ Session state maintained")
                    return True
                else:
                    print("‚ùå Session state lost")
                    return False
            else:
                print("‚ùå State synchronization failed")
                return False
                
        except Exception as e:
            print(f"‚ùå State synchronization error: {str(e)}")
            return False
    
    def print_final_results(self):
        """Print comprehensive test results"""
        print("\n" + "=" * 70)
        print("üèÅ COMPLETE ORCHESTRATION TEST RESULTS")
        print("=" * 70)
        
        passed_tests = sum(1 for _, result, _ in self.test_results if result)
        total_tests = len(self.test_results)
        success_rate = (passed_tests / total_tests) * 100
        
        for test_name, result, error in self.test_results:
            status = "‚úÖ PASSED" if result else "‚ùå FAILED"
            print(f"{status:<12} {test_name}")
            if error:
                print(f"             Error: {error}")
        
        print(f"\nüìä Overall Results: {passed_tests}/{total_tests} tests passed ({success_rate:.1f}%)")
        
        if success_rate >= 90:
            print("\nüéâ ORCHESTRATION SYSTEM IS PRODUCTION READY!")
            print("   ‚úÖ All core systems integrated successfully")
            print("   ‚úÖ Error handling and recovery working")
            print("   ‚úÖ Performance meets requirements")
            print("   ‚úÖ State management synchronized")
            
            print("\nüöÄ Ready for Frontend Integration:")
            print("   ‚Ä¢ Session management: POST /api/orchestration/sessions/start")
            print("   ‚Ä¢ Action processing: POST /api/orchestration/actions/process")
            print("   ‚Ä¢ Real-time updates: WS /api/orchestration/sessions/{id}/ws")
            print("   ‚Ä¢ Status monitoring: GET /api/orchestration/sessions/{id}/status")
            
        elif success_rate >= 70:
            print("\n‚ö†Ô∏è ORCHESTRATION SYSTEM NEEDS MINOR FIXES")
            print("   Most systems working but some issues detected")
            print("   Review failed tests and address before production")
            
        else:
            print("\n‚ùå ORCHESTRATION SYSTEM NEEDS MAJOR WORK")
            print("   Critical issues detected in core functionality")
            print("   Significant development required before deployment")


async def main():
    """Run the complete orchestration test suite"""
    print("üéÆ SoloRealms Complete AI Orchestration Test Suite")
    print("üéØ Testing: Session ‚Üí Action ‚Üí AI ‚Üí Parsing ‚Üí State ‚Üí Response")
    print("=" * 70)
    
    suite = OrchestrationTestSuite()
    await suite.run_all_tests()


if __name__ == "__main__":
    asyncio.run(main()) 